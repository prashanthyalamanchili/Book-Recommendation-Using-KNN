{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gi4oTp5LNrCH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from bokeh.plotting import figure, output_file, show\n",
        "from bokeh.palettes import magma\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
        "\n",
        "!unzip book-crossings.zip\n",
        "\n",
        "books_filename = 'BX-Books.csv'\n",
        "ratings_filename = 'BX-Book-Ratings.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYSA6VEYNvmR",
        "outputId": "6f4d62e1-2baf-444b-9830-1da30968d636"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-06 16:43:34--  https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.3.33, 172.67.70.149, 104.26.2.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.3.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26085508 (25M) [application/zip]\n",
            "Saving to: â€˜book-crossings.zipâ€™\n",
            "\n",
            "book-crossings.zip  100%[===================>]  24.88M  31.8MB/s    in 0.8s    \n",
            "\n",
            "2024-09-06 16:43:35 (31.8 MB/s) - â€˜book-crossings.zipâ€™ saved [26085508/26085508]\n",
            "\n",
            "Archive:  book-crossings.zip\n",
            "  inflating: BX-Book-Ratings.csv     \n",
            "  inflating: BX-Books.csv            \n",
            "  inflating: BX-Users.csv            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv data into dataframes\n",
        "df_books = pd.read_csv(\n",
        "    books_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "df_ratings = pd.read_csv(\n",
        "    ratings_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})\n"
      ],
      "metadata": {
        "id": "aw7GH98YNvwa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1- Find all the books ISBN with same title and author\n",
        "foo = df_books.groupby(['title', 'author']).agg(copies=('isbn', list), count=('isbn', 'count'))\n",
        "\n",
        "# 2- Update all the ratings to point to the 1st ISBN found for that book\n",
        "isbn_list = foo.query('count > 3')['copies'].tolist();\n",
        "for ids in isbn_list:\n",
        "  anchor, to_replace_list = ids[0], ids[1:]\n",
        "  df_ratings.loc[df_ratings['isbn'].isin(to_replace_list), 'isbn'] = anchor"
      ],
      "metadata": {
        "id": "ScaCD1cqNv1a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLEAN UP THE DATA\n",
        "\n",
        "duplicate_books = df_books.groupby(['title', 'author']).title.agg(['count']).reset_index().query('count > 1')\n",
        "duplicates_books_count = duplicate_books['count'].sum() - len(duplicate_books)\n",
        "\n",
        "duplicate_ratings = df_ratings.groupby(['isbn', 'user']).isbn.agg(['count']).reset_index().query('count > 1')\n",
        "duplicates_ratings_count = duplicate_ratings['count'].sum() - len(duplicate_ratings)\n",
        "\n",
        "## Modify the DF to drop duplicate or irrelevant rows\n",
        "df_books = df_books.drop_duplicates(subset=['title', 'author'])\n",
        "df_ratings = df_ratings.drop_duplicates(subset=['isbn', 'user'])\n",
        "\n",
        "print(\"Found and removed {:,} duplicate copies of books and {:,} duplicate copies of ratings\".format(duplicates_books_count, duplicates_ratings_count))\n",
        "\n",
        "## Books\n",
        "books_count_before = len(df_books)\n",
        "books_with_ratings = df_books.merge(df_ratings, on='isbn')\n",
        "grouped_by_isbn = books_with_ratings.groupby(['isbn', 'title']).rating.agg(['count', 'mean']).reset_index()\n",
        "books_min_count = 100\n",
        "acceptable_books = grouped_by_isbn.query('count >= {}'.format(books_min_count))['isbn'].tolist()\n",
        "grouped_by_isbn = grouped_by_isbn[grouped_by_isbn['isbn'].isin(acceptable_books)]\n",
        "df_books = df_books[df_books['isbn'].isin(acceptable_books)]\n",
        "books_count_after = len(df_books)\n",
        "b_percent_change = round((books_count_before-books_count_after)/books_count_before*100, 2)\n",
        "print('Removed {:,} rows ({}%) of books with less than {} reviews'.format(books_count_before - books_count_after, b_percent_change, books_min_count))\n",
        "\n",
        "## Users\n",
        "users_count_before = len(df_ratings)\n",
        "ratings_min_count = 200;\n",
        "df_ratings = df_ratings[df_ratings['isbn'].isin(acceptable_books)]\n",
        "acceptable_users = df_ratings.groupby(['user']).rating.agg(['count']).reset_index().query('count >= {}'.format(ratings_min_count))['user'].tolist()\n",
        "df_ratings = df_ratings[df_ratings['user'].isin(acceptable_users)]\n",
        "users_count_after = len(df_ratings)\n",
        "u_percent_change = round((users_count_before-users_count_after)/users_count_before*100,2)\n",
        "print('Removed {:,} rows ({}%) of user ratings with less than {} reviews per account or invalid books'.format(users_count_before - users_count_after, u_percent_change, ratings_min_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wTHXBjYNv4E",
        "outputId": "db31b821-9daa-4cc7-9c0c-214b27ca4512"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and removed 20,175 duplicate copies of books and 1,385 duplicate copies of ratings\n",
            "Removed 250,496 rows (99.72%) of books with less than 100 reviews\n",
            "Removed 1,142,576 rows (99.49%) of user ratings with less than 200 reviews per account or invalid books\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### REVIEWS AND USER BEHAVIOR GRAPHS AND VISUALS\n",
        "\n",
        "grouped_by_user = df_ratings.groupby(['user'])\n",
        "user_ratings = grouped_by_user['rating'].agg(['sum', 'count', 'mean']).reset_index()\n",
        "\n",
        "print('--- BASIC STATS\\n')\n",
        "user_count = len(grouped_by_user['user'])\n",
        "review_count = len(df_ratings)\n",
        "most_active_list = user_ratings.sort_values(by='count')\n",
        "most_active_user = most_active_list.iloc[-1];\n",
        "print('There is over {:,} reviews in the database written by {:,} users'.format(review_count, user_count))\n",
        "print('The most active user (ID: #{}) has written {:,} reviews\\n'.format(most_active_user.name, int(most_active_user['count'])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn9JSm3RNv6y",
        "outputId": "17d6fdc4-2dd5-4c9a-e824-aaf193d5ef73"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BASIC STATS\n",
            "\n",
            "There is over 5,819 reviews in the database written by 22 users\n",
            "The most active user (ID: #0) has written 635 reviews\n",
            "\n",
            "\n",
            "--- WHERE DO MOST OF OUR REVIEWS COME FROM?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FORMAT THE LAST DATA BEFORE CREATING MODAL\n",
        "# import csv data into dataframes\n",
        "df_books = pd.read_csv(\n",
        "    books_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "df_ratings = pd.read_csv(\n",
        "    ratings_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})\n",
        "\n",
        "df = df_ratings\n",
        "counts1 = df['user'].value_counts()\n",
        "counts2 = df['isbn'].value_counts()\n",
        "\n",
        "df = df[~df['user'].isin(counts1[counts1 < 200].index)]\n",
        "df = df[~df['isbn'].isin(counts2[counts2 < 100].index)]\n",
        "\n",
        "\n",
        "merged_df = pd.merge(right=df, left = df_books, on=\"isbn\")\n",
        "merged_df = merged_df.drop_duplicates(subset=[\"title\", \"user\"])\n",
        "\n",
        "books_features_pivot = merged_df.pivot(\n",
        "  index='title',\n",
        "  columns='user',\n",
        "  values='rating'\n",
        ").fillna(0)\n",
        "\n",
        "mat_books_features = csr_matrix(books_features_pivot.values)"
      ],
      "metadata": {
        "id": "e310BE5INv9c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## function to return recommended books - this will be tested\n",
        "def get_recommends(book = \"\", n = 5):\n",
        "  \"\"\"\n",
        "  make top n books recommendations\n",
        "  Parameters\n",
        "  ----------\n",
        "  book: str, name of user input book\n",
        "  n: int, top n recommendations\n",
        "  \"\"\"\n",
        "  # Prepare for model\n",
        "  pivot = books_features_pivot\n",
        "  titles = list(pivot.index.values)\n",
        "  data = pivot.values\n",
        "\n",
        "  def title_2_index(title):\n",
        "    ind = titles.index(title)\n",
        "    return data[ind,:]\n",
        "\n",
        "  def index_2_title(ind):\n",
        "    return titles[ind]\n",
        "\n",
        "\n",
        "  # Build model\n",
        "  model = NearestNeighbors(metric=\"cosine\",algorithm=\"brute\", p=2)\n",
        "  model.fit(data)\n",
        "\n",
        "  # Run model to get recommendations\n",
        "  idx = title_2_index(book)\n",
        "  distances, indices = model.kneighbors(\n",
        "    np.reshape(idx,[1,-1]),\n",
        "    n_neighbors=n+1\n",
        "  )\n",
        "\n",
        "  raw_recommends = sorted(\n",
        "    list(\n",
        "      zip(\n",
        "        indices.squeeze().tolist(),\n",
        "        distances.squeeze().tolist()\n",
        "      )\n",
        "    ),\n",
        "    key=lambda x: x[1]\n",
        "  )[1:]\n",
        "\n",
        "  # print results\n",
        "  recommended_books = []\n",
        "  print('Recommendations for {}:'.format(book))\n",
        "  for i, (idx, dist) in enumerate(raw_recommends):\n",
        "      dist = dist\n",
        "      recommended_books.append([index_2_title(idx), dist])\n",
        "      print('{0}: {1}, with distance of {2:,.2f}'.format(i+1, index_2_title(idx), dist))\n",
        "  print('-----------------')\n",
        "  return [book, recommended_books]"
      ],
      "metadata": {
        "id": "ypBU7UDJNwAb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_book_recommendation():\n",
        "  test_pass = True\n",
        "  recommends = get_recommends(\"The Queen of the Damned (Vampire Chronicles (Paperback))\", 10)\n",
        "  if recommends[0] != \"The Queen of the Damned (Vampire Chronicles (Paperback))\":\n",
        "    test_pass = False\n",
        "  recommended_books = [\"I'll Be Seeing You\", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True', 'The Lovely Bones: A Novel']\n",
        "  recommended_books_dist = [0.8, 0.77, 0.77, 0.77, 0.72]\n",
        "  recommended_books.reverse()\n",
        "  recommended_books_dist.reverse()\n",
        "\n",
        "  for i in range(2):\n",
        "    if recommends[1][i][0] not in recommended_books:\n",
        "      test_pass = False\n",
        "    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:\n",
        "      test_pass = False\n",
        "  if test_pass:\n",
        "    print(\"You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying!\")\n",
        "\n",
        "test_book_recommendation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIPy30x5PYlj",
        "outputId": "5cb13e32-310e-4442-a03d-e50c56f9eab8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for The Queen of the Damned (Vampire Chronicles (Paperback)):\n",
            "1: The Vampire Lestat (Vampire Chronicles, Book II), with distance of 0.52\n",
            "2: The Tale of the Body Thief (Vampire Chronicles (Paperback)), with distance of 0.54\n",
            "3: Interview with the Vampire, with distance of 0.73\n",
            "4: The Witching Hour (Lives of the Mayfair Witches), with distance of 0.74\n",
            "5: Catch 22, with distance of 0.79\n",
            "6: Lasher: Lives of the Mayfair Witches (Lives of the Mayfair Witches), with distance of 0.80\n",
            "7: The Gunslinger (The Dark Tower, Book 1), with distance of 0.81\n",
            "8: Neuromancer (Remembering Tomorrow), with distance of 0.81\n",
            "9: The Search, with distance of 0.83\n",
            "10: Purity in Death, with distance of 0.84\n",
            "-----------------\n",
            "You haven't passed yet. Keep trying!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPsIe0YJPYoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJJpYB7WPYrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lys9weK7NwDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8RnVeMiVNwGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IXLV95qNwI3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}